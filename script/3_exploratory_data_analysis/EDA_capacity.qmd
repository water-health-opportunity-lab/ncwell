---
title: "Exploratory Data Analysis (Capacity Module)"
format: html
toc: true
editor: visual
code-fold: true
self-contained: true
---

## 1. Highlight and a Summary

The below is a highlight for this exploratory data analysis of capacity module.

1.  We found outliers in some variables. Applying square root transformation or log transformation helps. However, the outliers may still be alarming after transformation. In this case, bottom coding or top coding (or both) is applied depending on whether there are outliers on the left and right tail. It is defined as setting the values above 98% percentile as 98 percentile (top coding) or those below 2% percentile as 2% (bottom coding). The histograms are provided in this case.
2.  It may be a better idea to transform English proficiency into a binary variable as it is zero-inflated.
3.  There exists multicollinearity among the set of transformed variables. If we remove Households and Population size from the set of variables, the multicollinearity problem will not be of concern.

The sample size of this dataset is 129169 and it has 25 variables.

```{r}
# load packages
require('sf')

# read data
data <- st_read('nc_grid_capacity.gpkg')

# total sample size
(n <- nrow(data))

# dimension
(p <- ncol(data) - 4)

# colnames
colnames(data)

# some transformation
for (j in 4:28) {
  data[[j]] <- as.numeric(data[[j]])
}
```

Next, we look into the variables in different groups.

## 2. Analysis for different groups of variables

Next, we present the exploratory data analysis for different groups of variables. We check missing percentage, mean, standard deviation (SD), median, and interquantile range (IQR) of the variables. For the groups more than 1 variable, we check multicollinearity through variance inflation factors (VIFs). Moreover, the histograms and boxplots of the variables are also presented. The proportions of outliers are also provided.

### **2.1 Race/ethnicity**

First, the descriptive statistics of the variables in race/ethnicity are presented below.

```{r}

# variable name
name.race <- c('Minority', 'English proficiency')

# check missing percentage
mp.race <- c(length(which(is.na(data$pct_minority) == TRUE)) / n, 
             length(which(is.na(data$pct_limited_english) == TRUE)) / n)

# check class
class.race <- c(class(data$pct_minority), 
                class(data$pct_limited_english))

# check mean
mean.race <- c(mean(data$pct_minority, na.rm = TRUE), 
               mean(data$pct_limited_english, na.rm = TRUE))

# check standard deviation
sd.race <- c(sd(data$pct_minority, na.rm = TRUE), 
             sd(data$pct_limited_english, na.rm = TRUE))

# check median
median.race <- c(median(data$pct_minority, na.rm = TRUE), 
                 median(data$pct_limited_english, na.rm = TRUE))

# check interquantile range
iqr <- function(x) paste0(round(quantile(na.omit(x), .25), 2), '-', 
                          round(quantile(na.omit(x), .75), 2))
iqr.race <- c(iqr(data$pct_minority), iqr(data$pct_limited_english))

# summary table
summary.race <- data.frame(Name = name.race, 
                           Class = class.race, 
                           Missing_Percentage = round(mp.race * 100, 2),
                           Mean = round(mean.race, 2),
                           Median = round(median.race, 2),
                           SD = round(sd.race, 2),
                           IQR = iqr.race)

print(summary.race)
race <- data.frame(data$pct_minority,
                   data$pct_limited_english)
```

The histograms of those two variables are presented below. Both of them are right-skewed but English proficiency is highly right-skewed.

```{r}
par(mfrow = c(1, 2))
hist(data$pct_minority, col = 'white', border = 'magenta',
     xlab = '',
     main = 'Minority')
hist(data$pct_limited_english, col = 'white', border = 'deepskyblue',
     xlab = '',
     main = 'English Proficiency')
```

The boxplots of the two variables in race/ethnicity are presented below. As we can see,

1.  There are a few outliers for Minority, mainly on the right tail of the distribution.
2.  In contrast, English proficiency has more outliers, at different levels.

```{r}
par(mfrow = c(1, 2))
boxplot(data$pct_minority, col = 'white', border = 'magenta',
        xlab = 'Minority')
boxplot(data$pct_limited_english, 
        xlab = 'English Proficiency',
        col = 'white', border = 'deepskyblue')
```

In specific, the percentage of outliers on the right-tail is shown below. They are defined as the observations that have distances greater than 1.5 times IQR from the 75% quantile. Indeed, around 17% of the English proficiency are outliers.

```{r}
# find the percentage of outliers on the right tail
right.whisker <- function(x) {
  n <- length(x)
  qf <- quantile(x, c(.25, .75), na.rm = TRUE)
  IQR <- qf[2] - qf[1]
  length(which(x > qf[2] + 1.5 * IQR)) / n
}

# percentage of outliers on the right tail
outlier.percent <- c(right.whisker(data$pct_minority),
                     right.whisker(data$pct_limited_english)) * 100 
names(outlier.percent) <- name.race
print(round(outlier.percent, 2))
```

In terms of English proficiency, we check its distribution on the right tail below. It may be a good idea to transform it into an ordered binary variable.

```{r}
quantile(na.omit(data$pct_limited_english), c(.8, .85, .9, .95))
summary(ifelse(data$pct_limited_english > 0, 1, 0))
data$bv_limited_english <- ifelse(data$pct_limited_english > 0, 1, 0)

oc.check <- function(x, level = .99, method = 'power', degree) {
  x[which(x == Inf)] <- NA
  x <- na.omit(x)
  cv <- qnorm(level)
  if (method == 'log') {
    x <- log(na.omit(x) + 1e-4)
  } else if (method == 'sqrt') {
    x <- sqrt(x)
  } else if (method == 'boxcox') {
    fit <- lm(x ~ 1)
    bc <- boxcox(fit, lambda = seq(2, 10, 0.1))
    best_lambda <- bc$x[which.max(bc$y)]
    x <- (x ^ best_lambda - 1) / best_lambda
  } else if (method == 'power') {
    x <- x ^ (degree)
  } else if (method == 'log10') {
    x <- log10(x + 1e-4)
  }
  n <- length(x)
  length(which(x > mean(x) + cv * sd(x) | x < mean(x) - cv * sd(x))) / n
}

coding <- function(x, alpha = 0.02, 
                     tail = c('left', 'right', 'both')) {
  lt <- quantile(x, alpha, na.rm = TRUE)
  rt <- quantile(x, 1 - alpha, na.rm = TRUE)
  
  if (tail == 'left') {
    x[which(x < lt)] <- lt
  } else if (tail == 'right') {
    x[which(x > rt)] <- rt
  } else {
    x[which(x < lt)] <- lt
    x[which(x > rt)] <- rt
  }
  
  return(x)
}
x1.trans <- race
```

Next, we check the spatial distribution of those two variables below.

```{r}
require('ggplot2')
ggplot(data = data) + geom_sf(aes(color = pct_minority)) + 
  theme_bw() + labs(title = "Minority") + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) +
  geom_sf(aes(color = as.factor(bv_limited_english), 
              fill = as.factor(bv_limited_english)), size = 0.5) +
  scale_fill_manual(values = c("magenta", "deepskyblue")) +
  scale_color_manual(values = c("magenta", "deepskyblue")) +
  theme_bw() +
  labs(title = 'Lack of English Proficiency (Binary)', 
       fill = 'Lack of English Proficiency (Binary)',
       color = 'Lack of English Proficiency (Binary)') +
  theme(panel.grid = element_blank())
```

### **2.2 Socioeconomic**

The summary statistics of the variables in the socioeconomic group are presented below.

```{r}

# variable name
name.socioeco <- c('Single-parent', 'Unemployment', 'Education', 'Poverty')

# check missing percentage
mp.socioeco <- c(length(which(is.na(data$pct_single_parent) == TRUE)) / n, 
                 length(which(is.na(data$pct_unemployed) == TRUE)) / n,
                 length(which(is.na(data$pct_no_college) == TRUE)) / n,
                 length(which(is.na(data$pct_poverty) == TRUE)) / n)

# check class
class.socioeco <- c(class(data$pct_single_parent), 
                    class(data$pct_unemployed),
                    class(data$pct_no_college),
                    class(data$pct_poverty))

# check mean
mean.socioeco <- c(mean(data$pct_single_parent, na.rm = TRUE), 
               mean(data$pct_unemployed, na.rm = TRUE),
               mean(data$pct_no_college, na.rm = TRUE),
               mean(data$pct_poverty, na.rm = TRUE))

# check standard deviation
sd.socioeco <- c(sd(data$pct_single_parent, na.rm = TRUE), 
             sd(data$pct_unemployed, na.rm = TRUE),
             sd(data$pct_no_college, na.rm = TRUE),
             sd(data$pct_poverty, na.rm = TRUE))

# check median
median.socioeco <- c(median(data$pct_single_parent, na.rm = TRUE), 
                 median(data$pct_unemployed, na.rm = TRUE),
                 median(data$pct_no_college, na.rm = TRUE),
                 median(data$pct_poverty, na.rm = TRUE))

# check interquantile range
iqr.socioeco <- c(iqr(data$pct_single_parent), 
                 iqr(data$pct_unemployed),
                 iqr(data$pct_no_college),
                 iqr(data$pct_poverty))

# summary table
summary.socioeco <- data.frame(Name = name.socioeco, 
                           Class = class.socioeco, 
                           Missing_Percentage = round(mp.socioeco * 100, 2),
                           Mean = round(mean.socioeco, 2),
                           Median = round(median.socioeco, 2),
                           SD = round(sd.socioeco, 2),
                           IQR = iqr.socioeco)

print(summary.socioeco)
require('car')
socioeco <- data.frame(data$pct_single_parent,
                       data$pct_unemployed, 
                       data$pct_no_college,
                       data$pct_poverty)
```

The histograms of the variables in the socioeconomic group are shown below.

```{r}
par(mfrow = c(2, 2))
hist(data$pct_single_parent, col = 'white', border = 'magenta',
     xlab = '',
     main = name.socioeco[1])
hist(data$pct_unemployed, col = 'white', border = 'deepskyblue',
     xlab = '',
     main = name.socioeco[2])
hist(data$pct_no_college, col = 'white', border = 'indianred1',
     xlab = '',
     main = name.socioeco[3])
hist(data$pct_poverty, col = 'white', border = 'slateblue',
     xlab = '',
     main = name.socioeco[4])
```

The boxplots of the variables in the socioeconomic group are presented below.

```{r}
par(mfrow = c(1, 2))
boxplot(data$pct_single_parent, col = 'white', border = 'magenta',
        xlab = name.socioeco[1])
boxplot(data$pct_unemployed, 
        xlab = name.socioeco[2],
        col = 'white', border = 'deepskyblue')
par(mfrow = c(1, 2))
boxplot(data$pct_no_college, 
        xlab = name.socioeco[3],
        col = 'white', border = 'indianred1')
boxplot(data$pct_poverty, 
        xlab = name.socioeco[4],
        col = 'white', border = 'slateblue')
```

Next, we find the percentage of outliers on the right-tail. We don't see alarming signs here in terms of outliers.

```{r}
# find the percentage of outliers on the right tail
right.whisker <- function(x) {
  n <- length(x)
  qf <- quantile(x, c(.25, .75), na.rm = TRUE)
  IQR <- qf[2] - qf[1]
  length(which(x > qf[2] + 1.5 * IQR)) / n
}

# percentage of outliers on the right tail
outlier.percent <- c(right.whisker(data$pct_single_parent),
                     right.whisker(data$pct_unemployed),
                     right.whisker(data$pct_no_college),
                     right.whisker(data$pct_poverty)) * 100 
names(outlier.percent) <- name.socioeco
print(round(outlier.percent, 2))
```

Next, we check whether we can do some transformation to resolve this issue, which considers log transformation and square root transformation. The idea is to cover a desired proportion of data (say, 98%) of normally behaved data under some transformation. According to the results below, we may need to consider square root transformation for education. However, for single-parent and unemployment, either one works well.

```{r}
# single-parent
oc.check(data$pct_single_parent, method = 'log')
oc.check(data$pct_single_parent, method = 'sqrt')
# unemployment
oc.check(data$pct_unemployed, method = 'log')
oc.check(data$pct_unemployed, method = 'sqrt')
# education
oc.check(data$pct_no_college, method = 'log')
oc.check(data$pct_no_college, method = 'sqrt')
```

Either transformation works for Unemployment and Single-parent. Next, we check if top coding works for Education. As we can see below, after such treatment, the distribution of Education appears well-behaved.

```{r}
# Education
x2.3.trans <- coding(sqrt(data$pct_no_college), tail = 'right')
oc.check(x2.3.trans, method = 'power', degree = 1) * 100
hist(x2.3.trans, col = 'white', border = 'magenta',
     main = name.socioeco[3], xlab = '')
x2.trans <- cbind(log(data$pct_single_parent + 1e-4), 
                  log(data$pct_unemployed + 1e-4), 
                  x2.3.trans, data$pct_poverty)
```

```{r}
ggplot(data = data) + geom_sf(aes(color = x2.trans[, 1])) + 
  theme_bw() + labs(title = paste0(name.socioeco[1], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x2.trans[, 2])) + 
  theme_bw() + labs(title = paste0(name.socioeco[2], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x2.trans[, 3])) + 
  theme_bw() + labs(title = paste0(name.socioeco[3], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x2.trans[, 4])) + 
  theme_bw() + labs(title = paste0(name.socioeco[4])) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')
```

### **2.3 Health risk**

The summary statistics of the variables in the health risk group are presented below.

```{r}
# variable name
name.health.risk <- c('Sex', 'Seniors', 'Youth', 'Pregnancy', 'Health insurance')

# check missing percentage
mp.health.risk <- c(length(which(is.na(data$pct_women) == TRUE)) / n, 
                    length(which(is.na(data$pct_over_65) == TRUE)) / n,
                    length(which(is.na(data$pct_under_17) == TRUE)) / n,
                    length(which(is.na(data$pct_women_gave_birth) == TRUE)) / n,
                    length(which(is.na(data$pct_insured) == TRUE)) / n)

# check class
class.health.risk <- c(class(data$pct_women), 
                       class(data$pct_over_65),
                       class(data$pct_under_17),
                       class(data$pct_women_gave_birth),
                       class(data$pct_insured))

# check mean
mean.health.risk <- c(mean(data$pct_women, na.rm = TRUE), 
                      mean(data$pct_over_65, na.rm = TRUE),
                      mean(data$pct_under_17, na.rm = TRUE),
                      mean(data$pct_women_gave_birth, na.rm = TRUE),
                      mean(data$pct_insured, na.rm = TRUE))

# check standard deviation
sd.health.risk <- c(sd(data$pct_women, na.rm = TRUE), 
                    sd(data$pct_over_65, na.rm = TRUE),
                    sd(data$pct_under_17, na.rm = TRUE),
                    sd(data$pct_women_gave_birth, na.rm = TRUE),
                    sd(data$pct_insured, na.rm = TRUE))

# check median
median.health.risk <- c(median(data$pct_women, na.rm = TRUE), 
                        median(data$pct_over_65, na.rm = TRUE),
                        median(data$pct_under_17, na.rm = TRUE),
                        median(data$pct_women_gave_birth, na.rm = TRUE),
                        median(data$pct_insured, na.rm = TRUE))

# check interquantile range
iqr.health.risk <- c(iqr(data$pct_women), 
                     iqr(data$pct_over_65),
                     iqr(data$pct_under_17),
                     iqr(data$pct_women_gave_birth),
                     iqr(data$pct_insured))

# summary table
summary.health.risk <- data.frame(Name = name.health.risk, 
                           Class = class.health.risk, 
                           Missing_Percentage = round(mp.health.risk * 100, 2),
                           Mean = round(mean.health.risk, 2),
                           Median = round(median.health.risk, 2),
                           SD = round(sd.health.risk, 2),
                           IQR = iqr.health.risk)

print(summary.health.risk)

require('car')
health.risk <- data.frame(data$pct_women,
                          data$pct_over_65, 
                          data$pct_under_17,
                          data$pct_women_gave_birth,
                          data$pct_insured)
```

Next, we check the histogram of the variables in the health risk group.

```{r}
par(mfrow = c(2, 3))
hist(data$pct_women, col = 'white', border = 'magenta',
     xlab = '',
     main = name.health.risk[1])
hist(data$pct_over_65, col = 'white', border = 'deepskyblue',
     xlab = '',
     main = name.health.risk[2])
hist(data$pct_under_17, col = 'white', border = 'indianred1',
     xlab = '',
     main = name.health.risk[3])
hist(data$pct_women_gave_birth, col = 'white', border = 'slateblue',
     xlab = '',
     main = name.health.risk[4])
hist(data$pct_insured, col = 'white', border = 'royalblue',
     xlab = '',
     main = name.health.risk[5])
```

We can observe that

1.  The distribution of Sex looks bell-shaped.
2.  The distributions of Seniors, Youth, and Pregnancy are right-skewed. It looks like there may be some outliers at the right tail for Pregnancy and Seniors.
3.  The distribution of Health insurance is left-skewed. There may exist some outliers at the left tail.

Next, we check the boxplots of the variables in the health risk group. According to the boxplots, there may have some outliers at the left and right tails of Sex. And there are some outliers at the right tail of Youth.

```{r}
par(mfrow = c(1, 2))
boxplot(data$pct_women, col = 'white', border = 'magenta',
        xlab = name.health.risk[1])
boxplot(data$pct_over_65, 
        xlab = name.health.risk[2],
        col = 'white', border = 'deepskyblue')
par(mfrow = c(1, 3))
boxplot(data$pct_under_17, 
        xlab = name.health.risk[3],
        col = 'white', border = 'indianred1')
boxplot(data$pct_women_gave_birth, 
        xlab = name.health.risk[4],
        col = 'white', border = 'slateblue')
boxplot(data$pct_insured, 
        xlab = name.health.risk[5],
        col = 'white', border = 'royalblue')
```

Last, we check the proportion of outliers as below. We don't see alarming signs here in terms of outliers.

```{r}
whisker <- function(x) {
  n <- length(x)
  qf <- quantile(x, c(.25, .75), na.rm = TRUE)
  IQR <- qf[2] - qf[1]
  length(which(x > qf[2] + 1.5 * IQR | x < qf[1] - 1.5 * IQR)) / n
}
# percentage of outliers on the right tail
outlier.percent <- c(whisker(data$pct_women),
                     whisker(data$pct_over_65),
                     whisker(data$pct_under_17),
                     whisker(data$pct_women_gave_birth),
                     whisker(data$pct_insured)) * 100 
names(outlier.percent) <- name.health.risk
print(round(outlier.percent, 2))
```

Similarly, we check whether we can apply some transformation to avoid this issue. As we can see,

1.  log transformation works for Sex, Seniors, Pregnancy
2.  log or square root transformation does not work for Health insurance.

```{r}
# Sex
oc.check(data$pct_women, method = 'log') 

# Seniors
oc.check(data$pct_over_65, method = 'log') 

# Pregnancy
oc.check(data$pct_women_gave_birth, method = 'log') 

# Health insurance
oc.check(data$pct_insured, method = 'log')
oc.check(data$pct_insured, method = 'sqrt')
```

Since outliers are mainly on the left for Health Insurance, we try if using bottom coding helps. According to the histogram below, we can see that the transformed variable appears more well-behaved.

```{r}
x3.5.trans <- coding(log(data$pct_insured + 1e-4), tail = 'left')
oc.check(x3.5.trans, method = 'power', degree = 1) * 100
hist(x3.5.trans, col = 'white', border = 'magenta',
     main = name.health.risk[5], xlab = '')
x3.trans <- cbind(log(data$pct_women + 1e-4), 
                  log(data$pct_over_65 + 1e-4), 
                  data$pct_under_17,
                  log(data$pct_women_gave_birth + 1e-4), 
                  x3.5.trans)
```

Next, we visualize the spatial distribution of those variables below.

```{r}
ggplot(data = data) + geom_sf(aes(color = x3.trans[, 1])) + 
  theme_bw() + labs(title = paste0(name.health.risk[1], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x3.trans[, 2])) + 
  theme_bw() + labs(title = paste0(name.health.risk[2], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x3.trans[, 3])) + 
  theme_bw() + labs(title = paste0(name.health.risk[3])) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x3.trans[, 4])) + 
  theme_bw() + labs(title = paste0(name.health.risk[4], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x3.trans[, 5])) + 
  theme_bw() + labs(title = paste0(name.health.risk[5], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')
```

### **2.4 Immigration status**

Next, we provide the descriptive statistics of the immigration status. As it has only one variable, we do not check multicollinearity.

```{r}

# variable name
name.is <- c('Nativity')

# check missing percentage
mp.is <- c(length(which(is.na(data$pct_us_born) == TRUE)) / n)

# check class
class.is <- c(class(data$pct_us_born))

# check mean
mean.is <- c(mean(data$pct_us_born, na.rm = TRUE))

# check standard deviation
sd.is <- c(sd(data$pct_us_born, na.rm = TRUE))

# check median
median.is <- c(median(data$pct_us_born, na.rm = TRUE))

# check interquantile range
iqr.is <- c(iqr(data$pct_us_born))

# summary table
summary.is <- data.frame(Name = name.is, 
                           Class = class.is, 
                           Missing_Percentage = round(mp.is * 100, 2),
                           Mean = round(mean.is, 2),
                           Median = round(median.is, 2),
                           SD = round(sd.is, 2),
                           IQR = iqr.is)

print(summary.is)
```

Next, we present the histogram and boxplot of Nativity. As we can see, the distribution of Nativity is highly left-skewed. Most of the regions are US-born.

```{r}
par(mfrow = c(1, 2))
hist(data$pct_us_born, col = 'white', border = 'magenta',
     xlab = '',
     main = name.is[1])
boxplot(data$pct_us_born, col = 'white', border = 'magenta',
        xlab = name.is[1])
```

We further check the percentage of outliers. Depending on the need for the robustness, analysis may need to accommodate those outliers.

```{r}
# percentage of outliers on the right tail
outlier.percent <- c(whisker(data$pct_us_born)) * 100 
names(outlier.percent) <- name.is
print(round(outlier.percent, 2))
```

Similarly, we check whether applying some transformation helps. As we may observe, there are still some outliers.

```{r}
oc.check(data$pct_us_born, method = 'log')
oc.check(data$pct_us_born, method = 'sqrt')
```

Since the outliers of Nativity are mainly on the left, we apply bottom coding. As we can see, after bottom coding, the distribution of the transformed Nativity looks more well-behaved.

```{r}
x4.trans <- coding(log(data$pct_us_born + 1e-4), tail = 'left')
oc.check(x4.trans, method = 'power', degree = 1) * 100
hist(x4.trans, col = 'white', border = 'magenta',
     main = name.is[1], xlab = '')
```

Last, we check its spatial distribution below.

```{r}
ggplot(data = data) + geom_sf(aes(color = x4.trans)) + 
  theme_bw() + labs(title = paste0(name.is[1], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')
```

### **2.5 Social cohesion**

The descriptive statistics of the variables in the social cohesion group are shown below.

```{r}
# function for summary statistics
summ <- function(x, names) {
  p <- ncol(x)
  n <- nrow(x)
  tab <- data.frame()
  for (j in 1:p) {
    x.j <- x[, j]
    info <- c(round(length(which(is.na(x.j) == TRUE)) / n * 100, 2),
              class(x.j),
              round(mean(x.j, na.rm = TRUE), 2),
              round(sd(x.j, na.rm = TRUE), 2),
              round(median(x.j, na.rm = TRUE), 2),
              iqr(x.j))
    tab <- rbind(tab, info)
  }
  tab <- cbind(names, tab)
  colnames(tab) <- c('Name', 'Missing Percentage', 'Class', 'Mean', 'SD', 'Median',
                     'IQR')
  print(tab)
}
names.social.cohesion <- c('Homeownership rate', 'Active commuting',
                           'Geographical mobility')
x.social.cohesion <- cbind(data$pct_owner_occupied, data$pct_active_commuting,
                           data$pct_no_move)
summ(x = x.social.cohesion, names = names.social.cohesion)
```

Next, we look at the histograms and boxplots of the variables in the social cohesion group. As we may observe, the distributions of active commuting, government jobs are right-skewed while those of Homeownership rate and geographical mobility are left-skewed. Among them, active commuting may have more extreme outliers than others.

```{r}
cols <- c('magenta', 'deepskyblue', 'indianred1', 'royalblue')
par(mfrow = c(1, 3))
for (j in 1:3) {
  hist(x.social.cohesion[, j], 
       col = 'white', border = cols[j],
       xlab = '',
       main = names.social.cohesion[j])
}
par(mfrow = c(1, 3))
for (j in 1:3) {
  boxplot(x.social.cohesion[, j], 
          col = 'white', border = cols[j],
          main = '',
          xlab = names.social.cohesion[j])
}
```

Next, we find the proportion of outliers to double-check. According to the results below, we can see that active commuting have many outliers.

```{r}
outlier.percent <- apply(x.social.cohesion, 2, whisker) * 100
names(outlier.percent) <- names.social.cohesion
print(round(outlier.percent, 2))
```

Next, we check whether we can do some transformation to avoid the outliers. From the results below, we see that log transformation works for Homeownership and Active commuting. However, either log or square root transformation does not work for Homeownership.

```{r}
# Homeownership
oc.check(data$pct_owner_occupied, method = 'log') 

# Active commuting
oc.check(data$pct_active_commuting, method = 'log') 

# Geographical mobility
oc.check(data$pct_no_move, method = 'log')
oc.check(data$pct_no_move, method = 'sqrt')
```

Since outliers are mainly on the left for geographical mobility, we check if bottom coding works for Geographical mobility. As we can see, the transformed variable looks more well-behaved.

```{r}
x5.3.trans <- coding(sqrt(data$pct_no_move), tail = 'left')
oc.check(x5.3.trans, method = 'power', degree = 1) * 100
hist(x5.3.trans, col = 'white', border = 'magenta',
     main = names.social.cohesion[3], xlab = '')
x5.trans <- cbind(log(data$pct_owner_occupied + 1e-4), 
                  log(data$pct_active_commuting + 1e-4), 
                  x5.3.trans)
```

Next, we visualize its spatial distribution below.

```{r}
ggplot(data = data) + geom_sf(aes(color = x5.trans[, 1])) + 
  theme_bw() + labs(title = paste0(names.social.cohesion[1], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x5.trans[, 2])) + 
  theme_bw() + labs(title = paste0(names.social.cohesion[2], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x5.trans[, 3])) + 
  theme_bw() + labs(title = paste0(names.social.cohesion[3], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')
```

### **2.6 Institution Capacity**

The summary statistics of institution capacity are presented below. Since this only has one variables, we do no check multicollinearity.

```{r}
names.ic <- c('Government jobs')
x.ic <- cbind(data$pct_gov_workers)
summ(x = x.ic, names = names.ic)
```

Next, we check its histogram and boxplot of institution capacity below. As we can see, the distribution of government jobs is right-skewed, with some outliers.

```{r}
par(mfrow = c(1, 2))
hist(x.ic, 
       col = 'white', border = cols[1], main = '',
       xlab = names.ic[j])
boxplot(x.ic, 
          col = 'white', border = cols[1],
          main = '',
          xlab = names.ic[1])
```

Next, we check the proportion of outliers below. We do not see many outliers here.

```{r}
outlier.percent <- apply(x.ic, 2, whisker) * 100
names(outlier.percent) <- names.ic
print(round(outlier.percent, 2))
```

Next, we check whether we can do some transformation to resolve this issue. From the results below, either log transformation or square root transformation works well.

```{r}
# Government jobs
oc.check(data$pct_gov_workers, method = 'log')
oc.check(data$pct_gov_workers, method = 'sqrt')
x6.trans <- sqrt(data$pct_gov_workers)
```

### **2.7 Built environment**

First, we check the summary statistics of the variables in the built environment below.

```{r}
names.built.environment <- c('Crowded housing', 'Plumbing', 'Home age')
x.built.environment <- cbind(data$pct_crowded_housing, data$pct_plumbing,
                           data$pct_new_home)
summ(x = x.built.environment, names = names.built.environment)
```

Next, we look at the histograms and boxplots of the variables in the built environment group. As we may observe, the distributions of crowded housing and home age are left-skewed while that of Plumbing is right-skewed. And, there exist some extreme outliers for those variables. For example, for Plumbing, it has an extreme outlier being zero.

```{r}
par(mfrow = c(1, 3))
for (j in 1:3) {
  hist(x.built.environment[, j], 
       col = 'white', border = cols[j],
       xlab = '',
       main = names.built.environment[j])
}
par(mfrow = c(1, 3))
for (j in 1:3) {
  boxplot(x.built.environment[, j], 
          col = 'white', border = cols[j],
          main = '',
          xlab = names.built.environment[j])
}
```

Next, we check the proportion of outliers below. According to the following results, there exist many outliers for crowded housing (**\> 10%**) and plumbing (\> 5%).

```{r}
outlier.percent <- apply(x.built.environment, 2, whisker) * 100
names(outlier.percent) <- names.built.environment
print(round(outlier.percent, 2))
```

Likewise, we check we can apply transformation to resolve this issue. We can see

1.  log transformation works for Crowded housing and Plumbing.
2.  square root transformation works for Home age.

```{r}
# Crowded housing
oc.check(data$pct_crowded_housing, method = 'log') 

# Plumbing
oc.check(data$pct_plumbing, method = 'log') 

# Home age
oc.check(data$pct_new_home, method = 'sqrt')

x7.trans <- cbind(log(data$pct_crowded_housing + 1e-4),
                  log(data$pct_plumbing + 1e-4),
                  sqrt(data$pct_new_home))
```

Next, we visualize their spatial distribution below.

```{r}
ggplot(data = data) + geom_sf(aes(color = x7.trans[, 1])) + 
  theme_bw() + labs(title = paste0(names.built.environment[1], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x7.trans[, 2])) + 
  theme_bw() + labs(title = paste0(names.built.environment[2], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x7.trans[, 3])) + 
  theme_bw() + labs(title = paste0(names.built.environment[3], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')
```

### **2.8 Other social determinants**

First, we check the summary statistics of the variables in this group. So, notice that there exist some data quality issues for population size and computer. Their maximums are INFINITY.

```{r}
names.osd <- c('Vehicle ownership', 'Internet', 'Computer', 
               'Population size', 'Housing units', 'Households')
x.osd <- cbind(data$pct_no_vehicle, data$pct_no_internet, data$pct_no_computer,
               data$pop_density, data$housing_units_density, 
               data$households_density)
summ(x = x.osd, names = names.osd)
max(na.omit(data$pct_no_internet))
max(na.omit(data$pct_no_computer))
```

After ignoring the values that do not make sense, the summary statistics are shown below.

```{r}
summ.noinf <- function(x, names) {
  p <- ncol(x)
  n <- nrow(x)
  tab <- data.frame()
  for (j in 1:p) {
    x.j <- x[, j]
    x.j[which(x.j == Inf)] <- NA
    info <- c(round(length(which(is.na(x.j) == TRUE)) / n * 100, 2),
              class(x.j),
              round(mean(x.j, na.rm = TRUE), 2),
              round(sd(x.j, na.rm = TRUE), 2),
              round(median(x.j, na.rm = TRUE), 2),
              iqr(x.j))
    tab <- rbind(tab, info)
  }
  tab <- cbind(names, tab)
  colnames(tab) <- c('Name', 'Missing Percentage', 'Class', 'Mean', 'SD', 'Median',
                     'IQR')
  print(tab)
}
summ.noinf(x = x.osd, names = names.osd)
```

Next, we check the histograms and boxplots of the variables in this group. All the variables here are highly right-skewed, with outliers on the right.

```{r}
cols <- c('magenta', 'deepskyblue', 'indianred1', 
          'royalblue', 'slateblue',  'salmon')
par(mfrow = c(2, 3))
for (j in 1:6) {
  x.j <- x.osd[, j]
  x.j[which(x.j == Inf)] <- NA
  hist(x.j, 
       col = 'white', border = cols[j],
       xlab = '',
       main = names.osd[j])
}
for (j in 1:6) {
  if (j == 1 | j == 4) {
    par(mfrow = c(1, 3))
  }
  x.j <- x.osd[, j]
  x.j[which(x.j == Inf)] <- NA
  boxplot(x.j, 
          col = 'white', border = cols[j],
          main = '',
          xlab = names.osd[j])
}
```

To check the details, their proportions of outliers are shown below. There are a few more outliers in vehicle ownership and computer though the messages here are not very alarming.

```{r}
outlier.percent <- apply(x.osd, 2, whisker) * 100
names(outlier.percent) <- names.osd
print(round(outlier.percent, 2))
```

Similarly, we check we can apply transformation to resolve this issue. We can observe

1.  log transformation works for Vehicle ownership, Population size, Housing units, and Households.
2.  square root transformation works for Internet and Computer.

```{r}
# Vehicle ownership
oc.check(data$pct_no_vehicle, method = 'log')

# Internet
oc.check(data$pct_no_internet, method = 'sqrt')

# Computer
oc.check(data$pct_no_computer, method = 'sqrt')

# Population size
oc.check(data$pop_density, method = 'log')

# Housing units
oc.check(data$housing_units_density, method = 'log')

# Households
oc.check(data$households_density, method = 'log')

x8.trans <- cbind(log(data$pct_no_vehicle + 1e-4),
                  sqrt(data$pct_no_internet),
                  sqrt(data$pct_no_computer),
                  log(data$pop_density + 1e-4),
                  log(data$housing_units_density + 1e-4),
                  log(data$households_density + 1e-4))
```

Next, we visualize their spatial distributions below.

```{r}
ggplot(data = data) + geom_sf(aes(color = x8.trans[, 1])) + 
  theme_bw() + labs(title = paste0(names.osd[1], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x8.trans[, 2])) + 
  theme_bw() + labs(title = paste0(names.osd[2], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x8.trans[, 3])) + 
  theme_bw() + labs(title = paste0(names.osd[3], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x8.trans[, 4])) + 
  theme_bw() + labs(title = paste0(names.osd[4], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x8.trans[, 5])) + 
  theme_bw() + labs(title = paste0(names.osd[5], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')

ggplot(data = data) + geom_sf(aes(color = x8.trans[, 6])) + 
  theme_bw() + labs(title = paste0(names.osd[6], ' (transformed)')) + 
  theme(panel.grid = element_blank()) +
  scale_color_gradient(low = "deepskyblue", high = "magenta", 
                       name = '',
                       na.value = 'grey')
```

## **3. Multicollinearity (Overall)**

In this section, we check multicollinearity of all the variables. As we can see, the multicollinearity problems occur only for Households and Population size. After removing one of them, this problem should be resolved.

```{r}
x.trans <- cbind(x1.trans, x2.trans, 
                 x3.trans, x4.trans, 
                 x5.trans, x6.trans,
                 x7.trans, x8.trans)
vifs <- c()
for (j in 1:ncol(x.trans)) {
  y.j <- unlist(x.trans[, j])
  x.j <- x.trans[, -j]
  y.j[which(y.j == Inf)] <- NA
  mod <- lm(y.j ~ ., data = as.data.frame(x.j))
  vifs[j] <- 1 / (1 - summary(mod)$r.squared)
}
names(vifs) <- colnames(x.trans) <- c('Poverty status', 'Pregnancy', 'Health insurance',
                 'Nativity', 'Geographical mobility', 'Government jobs',
                 'Minority', 'English proficiency', 'Single-parent', 
                 'Unemployment', 'Education', 'Sex', 'Seniors', 
                 'Youth', 'Homeownership rate', 'Active computing', 
                 'Crowded housing', 'Plumbing', 'Home age', 'Vehicle ownership',
                 'Internet', 'Computer', 'Population size', 'Housing units', 
                 'Households')
print(round(vifs, 2))
```

As we can observe, there exist serious multicollinearity among those transformed variables. Next, we try to get a set of variables with VIFs smaller than 10. If we remove Households and Population size from the set of variables, the multicollinearity problem will not be of concern.

```{r}
vifs0 <- vifs
pool <- 1:length(vifs)
nn <- c()
while (max(na.omit(vifs0)) > 10) {
  vifs0 <- c()
  pool <- 1:ncol(x.trans)
  for (j in pool) {
    y.j <- unlist(x.trans[, j])
    x.j <- x.trans[, -j]
    y.j[which(y.j == Inf)] <- NA
    mod <- lm(y.j ~ ., data = as.data.frame(x.j))
    vifs0[j] <- 1 / (1 - summary(mod)$r.squared)
  }
  if (max(na.omit(vifs0)) > 10) {
    if (colnames(x.trans)[which.max(vifs0)] == 'Internet') {
      nn <- c(nn, colnames(x.trans)[which(order(vifs0) == 2)])
    } else {
      nn <- c(nn, colnames(x.trans)[which.max(vifs0)])
    }
    x.trans <- x.trans[, - which.max(vifs0)]
  }
}
# which variables to remove
print(nn)
print(vifs0)
```
