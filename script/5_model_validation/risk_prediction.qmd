---
title: "Contamination Risk Prediction"
format: html
toc: true
editor: visual
code-fold: true
warning: false 
message: false
self-contained: true
tabset: true
---

```{r, warning=FALSE,echo=FALSE,message=FALSE,results='hide'}
# load packages
library("MASS")
library("dplyr")
library("factoextra")
library("exactextractr")
library("tigris")
library("ggplot2")
library("plotly")
library("sf")
library("tibble")
library("GGally")
library("cluster")
library("mclust")
library("randomForest")
library("caret")
library('pROC')
library('smotefamily')
library("gstat")
library('sp')

## read data
data <- st_read('nc_grid_validation.gpkg')
data$time <- as.numeric(as.Date(data$Date_Collected) - as.Date("2024-09-25"))
data <- data[, -c(1:15, 113)]
data <- st_transform(data, 4326)

# extract coordinates (for POINT geometries)
coords <- st_coordinates(data)

# add lon/lat as new columns
data$lon <- coords[,1]
data$lat <- coords[,2]

## data for analysis
data_analysis <- st_drop_geometry(data)
data_analysis <- data_analysis[, -c(1:3)]
data_analysis <- na.omit(data_analysis)
data_analysis$Coliform_Result_Binary <- as.factor(data_analysis$Coliform_Result_Binary)

```

## Introduction

We recently obtained well testing results for private wells in the western counties of North Carolina, with a focus on total coliform contamination. The presence of total coliform in drinking water indicates potential structural vulnerabilities in the water system, such as cracks or leaks, that may allow harmful microbes to enter. The dataset includes approximately 800 private wells.

In this report, we apply a random forest model to predict contamination risk based on three sets of predictors: (1) spatial location, (2) time since the hurricane Helene affecting North Carolina, and (3) roughly 100 additional variables derived from capacity, vulnerability, and hazard modules. The data will be divided into training and testing sets using a 4:1 ratio.

Note that the dataset is imbalanced.

```{r}
table(data_analysis$Coliform_Result_Binary)
```

In view of this imbalance, we will maximize the F1 score to achieve a balance between specificity and sensitivity. In specific, it is defined as

$$
F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$$

where the precision and recall are defined as

$$
\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}, 
\quad 
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
$$

The F1 score balances precision and recall by their harmonic mean. Precision measures how many predicted contaminated wells are truly contaminated, and recall measures how many actual contaminated wells are correctly identified. Maximizing the F1 score helps select a cutoff that captures most contaminated wells while limiting false alarms.

According to the results, random forest achieves a **moderate** prediction performance (an AUC of 0.63). And, we do not detect strong spatial dependence in the residuals.

## Random forest

First, we fit the random forest using \texttt{mtry = 9} and growing 1000 trees. To interpret the results, we present the variable importance plot below. Variable importance measures how much each variable contributes to the random forest’s performance. Mean Decrease Accuracy indicates how much the model’s accuracy drops if a variable is randomly shuffled, while Mean Decrease Gini reflects how much a variable helps separate classes by reducing node impurity (how mixed the classes are within the node). High values in either metric indicate variables with high importance.

```{r}
# set a random seed for reproducibility
set.seed(666)

# training and testing split
train_index <- createDataPartition(data_analysis$Coliform_Result_Binary, p = 0.8, list = FALSE)
train_data <- data_analysis[train_index, ]
test_data  <- data_analysis[-train_index, ]

# random forest
mod.rf <- randomForest(Coliform_Result_Binary ~ ., 
                         data = train_data, 
                         ntree = 1000,          
                         mtry = floor(sqrt(ncol(train_data)-1)), 
                         importance = TRUE)

# Variable importance plot
var_imp <- importance(mod.rf)

# Top 10 by MeanDecreaseAccuracy
top10_acc <- data.frame(
  Variable = rownames(var_imp),
  Importance = var_imp[, "MeanDecreaseAccuracy"]
) %>%
  arrange(desc(Importance)) %>%
  slice(1:10)

ggplot(top10_acc, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_col(fill = "magenta") +
  coord_flip() +
  labs(title = "Top 10 Variables by Mean Decrease Accuracy",
       x = "", y = "Mean Decrease Accuracy") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.y = element_text(face = "bold"),
    panel.grid = element_blank()   # remove grid lines
  )

# Top 10 by MeanDecreaseGini
top10_gini <- data.frame(
  Variable = rownames(var_imp),
  Importance = var_imp[, "MeanDecreaseGini"]
) %>%
  arrange(desc(Importance)) %>%
  slice(1:10)

ggplot(top10_gini, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_col(fill = "deepskyblue") +
  coord_flip() +
  labs(title = "Top 10 Variables by Mean Decrease Gini",
       x = "", y = "Mean Decrease Gini") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.y = element_text(face = "bold"),
    panel.grid = element_blank()   
  )
```

In terms of model accuracy, the high contributing variables are (1) time to when the hurricane hits NC state, (2) land cover, (3) temperature, (4) Actual evapotranspiration, and (5) Impact of concentrated animal feeding operation.

In terms of discriminatory power, the high contributing variables are (1) time to when the hurricane hits NC state, (2) pH, (3) longitude, (4) latitude, and (5) agricultural runoff.

Next, we try to determine the cutoff for the contamination risk and assess its prediction performance.

```{r}
# estimate risk
pred_probs <- predict(mod.rf, newdata = test_data, 
                      type = "prob")[,2]

# find the cutoff that maximizes F1score
roc_obj <- roc(response = test_data$Coliform_Result_Binary,
               predictor = pred_probs,
               levels = c("Absent", "Present")) 

thresholds <- seq(0, 1, by = 0.01)
f1_results <- data.frame(threshold = thresholds,
                         precision = NA,
                         recall = NA,
                         F1 = NA)

for(i in seq_along(thresholds)){
  thresh <- thresholds[i]
  pred_class <- factor(ifelse(pred_probs > thresh, "Present", "Absent"),
                       levels = c("Absent", "Present"))
  
  cm <- confusionMatrix(pred_class, as.factor(test_data$Coliform_Result_Binary), positive = "Present")
  
  precision <- cm$byClass["Pos Pred Value"]
  recall <- cm$byClass["Sensitivity"]
  f1 <- 2 * precision * recall / (precision + recall)
  
  f1_results$precision[i] <- precision
  f1_results$recall[i] <- recall
  f1_results$F1[i] <- f1
}

# Find threshold with max F1
best_f1 <- f1_results[which.max(f1_results$F1), ]
best_f1

pred_class <- ifelse(pred_probs > 0.33, 'Present', 'Absent')

# Confusion matrix
confusionMatrix(as.factor(pred_class), 
                as.factor(test_data$Coliform_Result_Binary),
                positive = 'Present')
# area under curve
auc(roc_obj)
```

The cutoff that maximizes F1 score is 0.33. The resulting model has an area under curve (AUC) of 0.6271, which is better than random guess. Overall, the model is moderately effective at predicting well contamination. It correctly identifies a fair number of contaminated wells, but it also misses some, meaning some unsafe wells could go undetected. At the same time, it classifies a number of safe wells as contaminated, which could lead to unnecessary testing or concern.

## Test for spatial dependence

To diagnose the model performance, we check the spatial dependence of the residuals. We check the sample variogram of the residuals of the random forest model.

```{r}
# Get predicted probabilities
probs <- predict(mod.rf, train_data, type = "prob")

# residuals
y <- train_data$Coliform_Result_Binary
resid <- c()
for (i in 1:nrow(probs)) {
  if (y[i] == 'Present') {
    resid[i] <- 1 - probs[i, 2]
  } else {
    resid[i] <- probs[i, 1]
  }
}
train_data$resid <- resid

# Compute empirical variogram of residuals
coordinates(train_data) <- ~ lon + lat   # makes it Spatial
vgm_resid <- variogram(resid ~ 1, train_data)

# Fit different theoretical models
vgm_sph <- fit.variogram(vgm_resid, model = vgm("Sph"))
vgm_exp <- fit.variogram(vgm_resid, model = vgm("Exp"))
vgm_gau <- fit.variogram(vgm_resid, model = vgm("Gau"))

# find the best model
sse_sph <- attr(vgm_sph, "SSErr")
sse_exp <- attr(vgm_exp, "SSErr")
sse_gau <- attr(vgm_gau, "SSErr")
sse_sph; sse_exp; sse_gau
```

We assume a exponential variogram model to describe the spatial dependence, detailed as follows.

$$
\gamma(h) = c_0 + c \left( 1 - \exp\left(-\frac{h}{a}\right) \right)
$$

Note that

-   \\(\\gamma(h)\\) stands for semivariogram, which measures how similar residuals are as a function of distance \\(h\\).

-   $a$ stands for the range (scale of spatial dependence), which controls how quickly the spatial correlation decays.

-   \\(c_0\\) stands for the nugget effect, which represents measurement error.

-   \\(c\\) stands for partial sill, which is the part of variance (\\(c_0 + c\\)) that is explained by spatial correlation.

The variogram fitted by exponential model is shown below. Note that the points are the sample variogram while the line represents the fitted variogram. Note that the variogram appears to fluctuate around a constant level. It suggests that the spatial dependence in the residuals may not be strong.

```{r}
vgm.mod <- fit.variogram(vgm_resid, model = vgm("Exp"))
print(vgm.mod)
plot(vgm_resid, vgm.mod, lty = 2, type = 'b', col = 'magenta',
     ylab = 'Semivariance', xlab = 'Distance',
     main = 'Variogram (exponential model)')
```

According to the estimation results, we see the partial sill is 0.017 and the nugget effect is 0.072. Only \\(0.017 / (0.070 + 0.017) = 20\\%\\) of the residual variance is due to spatial dependence. So, some spatial dependence exists in the residuals but they are relatively weak compared to the noise. Next, we conduct a formal statistical test for the spatial dependence using permutation test.

```{r}
set.seed(666)
nperm <- 1000
perm.psills <- numeric(nperm)
obs.psill <- vgm.mod$psill[2]
for (i in 1:nperm) {
  # Permute residuals
  train_data$resid.perm <- sample(train_data$resid)
  
  # Empirical variogram
  vg.perm <- variogram(resid.perm ~ 1, train_data)
  
  # Fit spherical model
  fit.perm <- fit.variogram(vg.perm, model = vgm("Exp"))
  
  # Record partial sill
  perm.psills[i] <- fit.perm$psill[2]
}
(p <- mean(perm.psills >= obs.psill))
```

According to the results above, we can see that the partial sill is not significant. So, it suggests that the spatial dependence is weak.
